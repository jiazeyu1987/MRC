response = self.client.messages.create(
                model=model,
                max_tokens=4096*6,
                messages=anthropic_messages,
                **kwargs
            )  调用失败: Streaming is required for operations that may take longer than 10 minutes. See https://github.com/anthropics/anthropic-sdk-python#long-requests for more details这个错误表明你的 API 调用可能需要超过 10 分钟才能完成，Anthropic SDK 要求这种长时间运行的操作必须使用流式响应（streaming）。
以下是解决方案：
方案 1: 启用流式响应（推荐）
pythonresponse = self.client.messages.create(
    model=model,
    max_tokens=4096*6,
    messages=anthropic_messages,
    stream=True,  # 启用流式响应
    **kwargs
)

# 处理流式响应
full_response = ""
for event in response:
    if event.type == "content_block_delta":
        if event.delta.type == "text_delta":
            full_response += event.delta.text
            print(event.delta.text, end="", flush=True)  # 实时打印
方案 2: 使用 stream manager（更简洁）
pythonwith self.client.messages.stream(
    model=model,
    max_tokens=4096*6,
    messages=anthropic_messages,
    **kwargs
) as stream:
    for text in stream.text_stream:
        print(text, end="", flush=True)
    
    # 获取完整响应
    final_response = stream.get_final_message()
方案 3: 完整的流式处理示例
pythondef call_claude_with_streaming(self, messages, model="claude-sonnet-4-20250514"):
    """带流式响应的 Claude API 调用"""
    try:
        full_text = ""
        
        with self.client.messages.stream(
            model=model,
            max_tokens=4096*6,
            messages=messages,
        ) as stream:
            # 实时处理文本块
            for text in stream.text_stream:
                full_text += text
                print(text, end="", flush=True)
            
            # 获取最终消息对象（包含所有元数据）
            final_message = stream.get_final_message()
            
        return {
            "text": full_text,
            "message": final_message,
            "usage": final_message.usage
        }
        
    except Exception as e:
        print(f"\n调用失败: {e}")
        return None
方案 4: 处理不同类型的内容块
pythonresponse = self.client.messages.create(
    model=model,
    max_tokens=4096*6,
    messages=anthropic_messages,
    stream=True,
    **kwargs
)

full_response = []
for event in response:
    if event.type == "content_block_start":
        print(f"\n[内容块开始: {event.content_block.type}]")
    
    elif event.type == "content_block_delta":
        if event.delta.type == "text_delta":
            print(event.delta.text, end="", flush=True)
            full_response.append(event.delta.text)
    
    elif event.type == "message_stop":
        print("\n[消息完成]")

final_text = "".join(full_response)
为什么会出现这个错误？

max_tokens=4096*6 (24,576 tokens) 可能导致生成非常长的响应
长响应 + 复杂处理可能超过 10 分钟
Anthropic SDK 默认超时是 10 分钟，超过必须用 streaming

其他建议

减少 max_tokens（如果不需要那么长）:

pythonmax_tokens=4096  # 而不是 4096*6

检查消息长度：确保 anthropic_messages 不会太长
添加超时处理：

pythonfrom anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPT
import asyncio

# 设置更长的超时（如果不用 streaming）
client = Anthropic(timeout=600.0)  # 10 分钟
使用流式响应不仅能解决超时问题，还能让用户实时看到生成的内容，提供更好的用户体验！